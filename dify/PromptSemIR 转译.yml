app:
  description: ''
  icon: ğŸ¤–
  icon_background: '#FFEAD5'
  mode: workflow
  name: PromptSemIR è½¬è¯‘
  use_icon_as_answer_icon: false
dependencies:
- current_identifier: null
  type: marketplace
  value:
    marketplace_plugin_unique_identifier: langgenius/gemini:0.7.1@48bf314aad49c68acee6545f34b6ddb652c33e7da457dfb197ac514065e776e4
    version: null
kind: app
version: 0.5.0
workflow:
  conversation_variables: []
  environment_variables: []
  features:
    file_upload:
      allowed_file_extensions:
      - .JPG
      - .JPEG
      - .PNG
      - .GIF
      - .WEBP
      - .SVG
      allowed_file_types:
      - image
      allowed_file_upload_methods:
      - local_file
      - remote_url
      enabled: false
      fileUploadConfig:
        audio_file_size_limit: 50
        batch_count_limit: 5
        file_size_limit: 15
        image_file_batch_limit: 10
        image_file_size_limit: 10
        single_chunk_attachment_limit: 10
        video_file_size_limit: 100
        workflow_file_upload_limit: 10
      image:
        enabled: false
        number_limits: 3
        transfer_methods:
        - local_file
        - remote_url
      number_limits: 3
    opening_statement: ''
    retriever_resource:
      enabled: true
    sensitive_word_avoidance:
      enabled: false
    speech_to_text:
      enabled: false
    suggested_questions: []
    suggested_questions_after_answer:
      enabled: false
    text_to_speech:
      enabled: false
      language: ''
      voice: ''
  graph:
    edges:
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: start
        targetType: code
      id: 1766934024082-source-1766934027460-target
      source: '1766934024082'
      sourceHandle: source
      target: '1766934027460'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: code
        targetType: llm
      id: 1766934027460-source-1766934029593-target
      source: '1766934027460'
      sourceHandle: source
      target: '1766934029593'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: llm
        targetType: end
      id: 1766934029593-source-1766934704811-target
      source: '1766934029593'
      sourceHandle: source
      target: '1766934704811'
      targetHandle: target
      type: custom
      zIndex: 0
    nodes:
    - data:
        selected: false
        title: ç”¨æˆ·è¾“å…¥
        type: start
        variables:
        - allowed_file_extensions: []
          allowed_file_types:
          - document
          allowed_file_upload_methods:
          - local_file
          - remote_url
          default: ''
          hint: ''
          label: promptsemir_json
          max_length: 102400
          options: []
          placeholder: ''
          required: true
          type: paragraph
          variable: promptsemir_json
        - hint: ''
          label: target_llm_preference
          max_length: 102400
          options: []
          placeholder: ''
          required: false
          type: paragraph
          variable: target_llm_preference
        - default: ''
          hint: ''
          label: strict_mode
          max_length: 48
          options: []
          placeholder: ''
          required: true
          type: checkbox
          variable: strict_mode
      height: 161
      id: '1766934024082'
      position:
        x: 80
        y: 282
      positionAbsolute:
        x: 80
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 242
    - data:
        code: "import json\n\ndef main(promptsemir_json: str, strict_mode: bool) ->\
          \ dict:\n    \"\"\"\n    åŠŸèƒ½ï¼šä» PromptSemIR å®Œæ•´æ–‡ä»¶ä¸­æå–ç”¨äºè½¬è¯‘çš„â€œå‡€è·â€è¯­ä¹‰è§†å›¾ã€‚\n    é€»è¾‘ï¼š\n\
          \    1. è§£æè¾“å…¥ JSONã€‚\n    2. ç¡®å®šæ•°æ®æºï¼šä¼˜å…ˆä½¿ç”¨ final_view (å·²åº”ç”¨ Patch)ï¼Œé™çº§ä½¿ç”¨ promptSem\
          \ (è‰ç¨¿)ã€‚\n    3. è¿‡æ»¤ï¼šæ ¹æ® strict_mode å†³å®šæ˜¯å¦ä¸¢å¼ƒ inferred/projected å±‚ã€‚\n    4. æå–åŸæ–‡ç‰‡æ®µï¼šç”¨äº\
          \ Tone Referenceã€‚\n    5. åºåˆ—åŒ–è¾“å‡ºã€‚\n    \"\"\"\n    \n    # =================\
          \ 1. å®‰å…¨è§£æ JSON =================\n    data = {}\n    # Dify æœ‰æ—¶ä¼šæ ¹æ®ä¸Šæ¸¸èŠ‚ç‚¹ç±»å‹è‡ªåŠ¨è½¬\
          \ dictï¼Œæœ‰æ—¶ä¼  strï¼Œéœ€å…¼å®¹\n    if isinstance(promptsemir_json, dict):\n       \
          \ data = promptsemir_json\n    else:\n        try:\n            # å…¼å®¹ç©ºå­—ç¬¦ä¸²æƒ…å†µ\n\
          \            if not promptsemir_json or not str(promptsemir_json).strip():\n\
          \                return {\"semantic_view_str\": \"{}\", \"raw_snippet_hint\"\
          : \"\"}\n            data = json.loads(promptsemir_json)\n        except\
          \ Exception as e:\n            # è§£æå¤±è´¥æ—¶ä¸æŠ¥é”™ä¸­æ–­ï¼Œè€Œæ˜¯è¿”å›é”™è¯¯æç¤ºç»™ LLMï¼Œè®© LLM å†³å®šå¦‚ä½•å¤„ç†\n\
          \            return {\n                \"semantic_view_str\": json.dumps({\"\
          error\": f\"JSON parse failed: {str(e)}\"}, ensure_ascii=False),\n     \
          \           \"raw_snippet_hint\": \"\"\n            }\n\n    # =================\
          \ 2. ç¡®å®šè¯­ä¹‰æº (Source of Truth) =================\n    # final_view æ˜¯â€œç‰©åŒ–è§†å›¾â€ï¼ŒåŒ…å«äº†\
          \ Patch åçš„ç»“æœï¼Œæ˜¯ç¬¬ä¸€ä¼˜å…ˆçº§\n    semantic_source = data.get(\"final_view\")\n  \
          \  \n    # å¦‚æœ final_view ä¸å­˜åœ¨ï¼ˆä¾‹å¦‚æ˜¯åˆšç¼–è¯‘å®Œçš„ä¸­é—´æ€ï¼‰ï¼Œåˆ™å›é€€åˆ° promptSem\n    if not semantic_source:\n\
          \        semantic_source = data.get(\"promptSem\", {})\n\n    # =================\
          \ 3. ä¸¥æ ¼æ¨¡å¼è¿‡æ»¤ (Strict Mode) =================\n    # å¤„ç† Dify Checkbox å¯èƒ½ä¼ å…¥çš„ç±»å‹å·®å¼‚\n\
          \    is_strict = False\n    if isinstance(strict_mode, bool):\n        is_strict\
          \ = strict_mode\n    elif isinstance(strict_mode, str):\n        is_strict\
          \ = strict_mode.lower() == 'true'\n\n    filtered_data = {}\n    \n    #\
          \ [Core] æ°¸è¿œä¿ç•™\n    # ä½¿ç”¨ .get() é˜²æ­¢é”®ä¸å­˜åœ¨æŠ¥é”™\n    filtered_data[\"core_semantics\"\
          ] = semantic_source.get(\"core_semantics\", {})\n    \n    # [Derived &\
          \ Augmentation] ä»…åœ¨éä¸¥æ ¼æ¨¡å¼ä¸‹ä¿ç•™\n    if not is_strict:\n        filtered_data[\"\
          derived_semantics\"] = semantic_source.get(\"derived_semantics\", {})\n\
          \        filtered_data[\"augmentation_plan\"] = semantic_source.get(\"augmentation_plan\"\
          , {})\n\n    # ================= 4. æå–åŸæ–‡ç‰‡æ®µ (Tone Hint) =================\n\
          \    # è·¯å¾„ï¼šsource_prompt -> raw\n    # ç›®çš„ï¼šç»™ LLM æä¾›â€œè¯­æ°”å‚è€ƒâ€ï¼Œä½†ä¸ä½œä¸ºè¯­ä¹‰ä¾æ®\n    source_obj\
          \ = data.get(\"source_prompt\", {})\n    raw_text = source_obj.get(\"raw\"\
          , \"\")\n    if not isinstance(raw_text, str):\n        raw_text = \"\"\n\
          \        \n    # æˆªå–å‰ 300 å­—ç¬¦ï¼Œå»é™¤é¦–å°¾ç©ºç™½\n    raw_snippet_hint = raw_text.strip()[:300]\n\
          \    if len(raw_text) > 300:\n        raw_snippet_hint += \"...\"\n\n  \
          \  # ================= 5. è¾“å‡ºåºåˆ—åŒ– =================\n    return {\n      \
          \  # é‡ç‚¹ï¼šensure_ascii=False ä¿è¯ä¸­æ–‡ä¸ä¹±ç ï¼Œindent=2 ä¿è¯ LLM æ˜“è¯»\n        \"semantic_view_str\"\
          : json.dumps(filtered_data, ensure_ascii=False, indent=2),\n        \"raw_snippet_hint\"\
          : raw_snippet_hint\n    }"
        code_language: python3
        desc: ''
        outputs:
          raw_snippet_hint:
            children: null
            type: string
          semantic_view_str:
            children: null
            type: string
        selected: true
        title: Semantic Filter & Flattener
        type: code
        variables:
        - value_selector:
          - '1766934024082'
          - promptsemir_json
          value_type: string
          variable: promptsemir_json
        - value_selector:
          - '1766934024082'
          - strict_mode
          value_type: boolean
          variable: strict_mode
      height: 52
      id: '1766934027460'
      position:
        x: 386.54120281732264
        y: 287.9679743657389
      positionAbsolute:
        x: 386.54120281732264
        y: 287.9679743657389
      selected: true
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 242
    - data:
        context:
          enabled: false
          variable_selector: []
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: gemini-3-pro-preview
          provider: langgenius/gemini/google
        prompt_template:
        - id: 60ba5c38-5d1b-4e34-bed4-fbe982097eaa
          role: system
          text: "### Role\nä½ æ˜¯ä¸€åèµ„æ·±çš„ Prompt Engineerã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç»“æ„åŒ–çš„ã€PromptSemIR è¯­ä¹‰è§†å›¾ã€‘ï¼ˆJSONï¼‰è¿˜åŸä¸ºä¸€ä»½é«˜è´¨é‡çš„ã€è‡ªç„¶è¯­è¨€\
            \ Promptã€‘ã€‚\n\n### æ ¸å¿ƒåŸåˆ™ (Critical Principles)\n1.  **è¯­è¨€ä¸€è‡´æ€§ (Language Consistency)**ï¼š\n\
            \    * **æ£€æµ‹è¾“å…¥è¯­è¨€**ï¼šåˆ†æ `core_semantics` ä¸­ä½¿ç”¨çš„è¯­è¨€ï¼ˆè¿™é‡Œæ˜¯ä¸­æ–‡ï¼‰ã€‚\n    * **å¼ºåˆ¶è¾“å‡ºåŒè¯­è¨€**ï¼šä½ ç”Ÿæˆçš„\
            \ Prompt ä¸­çš„æ‰€æœ‰æŒ‡ä»¤ã€æ ‡é¢˜ã€æè¿°ã€è§’è‰²å®šä¹‰**å¿…é¡»ä½¿ç”¨ä¸­æ–‡**ã€‚ç»å¯¹ç¦æ­¢å°†ä¸­æ–‡æ„å›¾ç¿»è¯‘æˆè‹±æ–‡æŒ‡ä»¤ï¼ˆä¾‹å¦‚ï¼šä¸è¦æŠŠâ€œè§’è‰²â€å†™æˆâ€œ# Roleâ€ï¼‰ã€‚\n\
            \n2.  **æ¥å£åˆšæ€§ (Schema Rigidity)**ï¼š\n    * **å¤åˆ¶ç²˜è´´åŸåˆ™**ï¼šå¯¹äº `output_spec` ä¸­å®šä¹‰çš„\
            \ JSON ç»“æ„ï¼Œä½ å¿…é¡»**é€å­—å¤åˆ¶**ï¼Œç¦æ­¢åšä»»ä½•â€œä¼˜åŒ–â€æˆ–â€œç®€åŒ–â€ã€‚\n    * **ç¦æ­¢ç±»å‹è½¬æ¢**ï¼šå¦‚æœåŸå®šä¹‰æ˜¯ Objectï¼ˆå¦‚\
            \ `data_quality`ï¼‰ï¼Œç»å¯¹ä¸èƒ½æŠŠå®ƒæ”¹æˆ Stringã€‚\n    * **ç¦æ­¢é”®åä¿®æ”¹**ï¼šå¦‚æœåŸå®šä¹‰æ˜¯ `timeline`ï¼Œç»å¯¹ä¸èƒ½æ”¹æˆ\
            \ `cycle`ã€‚\n\n### è½¬è¯‘æ­¥éª¤\n\n#### Step 1: è§’è‰²ä¸èƒŒæ™¯ (Role & Context)\n* ç”¨**ä¸­æ–‡**å®šä¹‰è§’è‰²ï¼ˆå¦‚\
            \ `# è§’è‰²`ï¼‰ã€‚\n* æ ¹æ® `intent` å’Œ `raw_hint` è¿˜åŸèƒŒæ™¯ã€‚\n\n#### Step 2: å˜é‡æ³¨å…¥\n* ä¿æŒå˜é‡åä¸å˜ï¼ˆå¦‚\
            \ `{{kpi_table}}`ï¼‰ã€‚\n* ç”¨**ä¸­æ–‡**æè¿°å˜é‡ç”¨é€”ã€‚\n\n#### Step 3: é€»è¾‘ä¸çº¦æŸ\n* å°† `constraints`\
            \ è½¬åŒ–ä¸º**ä¸­æ–‡**æŒ‡ä»¤ï¼ˆå¦‚ `## çº¦æŸæ¡ä»¶`ï¼‰ã€‚\n* è´Ÿé¢çº¦æŸä½¿ç”¨åŠ ç²—å¼ºè°ƒã€‚\n\n#### Step 4: è¾“å‡ºè§„èŒƒè¿˜åŸ (Output\
            \ Spec)\n* **è­¦å‘Š**ï¼šè¿™æ˜¯æœ€å®¹æ˜“å‡ºé”™çš„åœ°æ–¹ã€‚\n* è¯·ç›´æ¥ä» Semantic View ä¸­æå– JSON ç»“æ„ï¼Œ**åŸæ ·**æ”¾å…¥\
            \ Prompt çš„è¾“å‡ºè¦æ±‚ä¸­ã€‚\n* æ·»åŠ æŒ‡ä»¤ï¼šâ€œè¾“å‡ºå¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹ JSON ç»“æ„ï¼Œä¸è¦ä¿®æ”¹å­—æ®µåï¼Œä¸è¦ä½¿ç”¨ Markdown ä»£ç å—â€ã€‚\n\
            \n### è¾“å‡ºæ ¼å¼\nç›´æ¥è¾“å‡ºç”Ÿæˆçš„ä¸­æ–‡ Prompt å†…å®¹ã€‚"
        - id: f5fca28f-13e7-42a3-bd4f-b3792ab5b571
          role: user
          text: 'ã€è¯­ä¹‰è§†å›¾ (Semantic View)ã€‘

            {{#1766934027460.semantic_view_str#}}


            ã€å‚è€ƒè¯­æ°” (Raw Hint)ã€‘

            (åŸ Prompt å¼€å¤´ç‰‡æ®µï¼Œä»…ä¾›å‚è€ƒè¯­æ°”ï¼Œä¸è¦ç…§æŠ„å†…å®¹)

            {{#1766934027460.raw_snippet_hint#}}


            ã€ç›®æ ‡æ¨¡å‹åå¥½ (Target Preference)ã€‘

            {{#1766934024082.target_llm_preference#}}


            è¯·ç”Ÿæˆæœ€ç»ˆçš„ Promptï¼š'
        selected: false
        title: LLM
        type: llm
        vision:
          enabled: false
      height: 88
      id: '1766934029593'
      position:
        x: 684
        y: 287.9679743657389
      positionAbsolute:
        x: 684
        y: 287.9679743657389
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 242
    - data:
        outputs:
        - value_selector:
          - '1766934029593'
          - text
          value_type: string
          variable: text
        selected: false
        title: è¾“å‡º
        type: end
      height: 88
      id: '1766934704811'
      position:
        x: 986
        y: 282
      positionAbsolute:
        x: 986
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 242
    viewport:
      x: 120.56357508825027
      y: 296.2315662361055
      zoom: 0.3917485934746727
  rag_pipeline_variables: []
